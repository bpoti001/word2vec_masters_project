{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import struct\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VocabItem:\n",
    "    def __init__(self, word):\n",
    "        self.word = word\n",
    "        self.count = 0\n",
    "        self.path = None # Path (list of indices) from the root to the word (leaf)\n",
    "        self.code = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, fi, min_count):\n",
    "        vocab_items = []\n",
    "        vocab_hash = {}\n",
    "        word_count = 0\n",
    "        fi = open(fi, 'r')\n",
    "\n",
    "        # Add special tokens <bol> (beginning of line) and <eol> (end of line)\n",
    "        for token in ['<bol>', '<eol>']:\n",
    "            vocab_hash[token] = len(vocab_items)\n",
    "            vocab_items.append(VocabItem(token))\n",
    "\n",
    "        for line in fi:\n",
    "            tokens = line.split()\n",
    "            for token in tokens:\n",
    "                if token not in vocab_hash:\n",
    "                    vocab_hash[token] = len(vocab_items)\n",
    "                    vocab_items.append(VocabItem(token))\n",
    "                    \n",
    "                #assert vocab_items[vocab_hash[token]].word == token, 'Wrong vocab_hash index'\n",
    "                vocab_items[vocab_hash[token]].count += 1\n",
    "                word_count += 1\n",
    "            \n",
    "                if word_count % 10000 == 0:\n",
    "                    sys.stdout.write(\"\\rReading word %d\" % word_count)\n",
    "                    sys.stdout.flush()\n",
    "\n",
    "            # Add special tokens <bol> (beginning of line) and <eol> (end of line)\n",
    "            vocab_items[vocab_hash['<bol>']].count += 1\n",
    "            vocab_items[vocab_hash['<eol>']].count += 1\n",
    "            word_count += 2\n",
    "\n",
    "        self.bytes = fi.tell()\n",
    "        self.vocab_items = vocab_items         # List of VocabItem objects\n",
    "        self.vocab_hash = vocab_hash           # Mapping from each token to its index in vocab\n",
    "        self.word_count = word_count           # Total number of words in train file\n",
    "\n",
    "        # Add special token <unk> (unknown),\n",
    "        # merge words occurring less than min_count into <unk>, and\n",
    "        # sort vocab in descending order by frequency in train file\n",
    "        self.__sort(min_count)\n",
    "\n",
    "        #assert self.word_count == sum([t.count for t in self.vocab_items]), 'word_count and sum of t.count do not agree'\n",
    "        print 'Total words in training file: %d' % self.word_count\n",
    "        print 'Total bytes in training file: %d' % self.bytes\n",
    "        print 'Vocab size: %d' % len(self)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.vocab_items[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.vocab_items)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.vocab_items)\n",
    "\n",
    "    def __contains__(self, key):\n",
    "        return key in self.vocab_hash\n",
    "\n",
    "    def __sort(self, min_count):\n",
    "        tmp = []\n",
    "        tmp.append(VocabItem('<unk>'))\n",
    "        unk_hash = 0\n",
    "        \n",
    "        count_unk = 0\n",
    "        for token in self.vocab_items:\n",
    "            if token.count < min_count:\n",
    "                count_unk += 1\n",
    "                tmp[unk_hash].count += token.count\n",
    "            else:\n",
    "                tmp.append(token)\n",
    "\n",
    "        tmp.sort(key=lambda token : token.count, reverse=True)\n",
    "\n",
    "        # Update vocab_hash\n",
    "        vocab_hash = {}\n",
    "        for i, token in enumerate(tmp):\n",
    "            vocab_hash[token.word] = i\n",
    "\n",
    "        self.vocab_items = tmp\n",
    "        self.vocab_hash = vocab_hash\n",
    "\n",
    "        print\n",
    "        print 'Unknown vocab size:', count_unk\n",
    "\n",
    "    def indices(self, tokens):\n",
    "        return [self.vocab_hash[token] if token in self else self.vocab_hash['<unk>'] for token in tokens]\n",
    "        \n",
    "class UnigramTable:\n",
    "    \"\"\"\n",
    "    A list of indices of tokens in the vocab following a power law distribution,\n",
    "    used to draw negative samples.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab):\n",
    "        vocab_size = len(vocab)\n",
    "        power = 0.75\n",
    "        norm = sum([math.pow(t.count, power) for t in vocab]) # Normalizing constant\n",
    "        print norm\n",
    "        table_size = 1e8 # Length of the unigram table\n",
    "        print table_size\n",
    "        table = np.zeros(table_size, dtype=np.uint32)\n",
    "\n",
    "        print 'Filling unigram table'\n",
    "        p = 0 # Cumulative probability\n",
    "        i = 0\n",
    "        for j, unigram in enumerate(vocab):\n",
    "            #print \"j\",j\n",
    "            #print \"unigram\",unigram\n",
    "            p += float(math.pow(unigram.count, power))/norm\n",
    "            #print \"propablity\", p\n",
    "            while i < table_size and float(i) / table_size < p:\n",
    "                table[i] = j\n",
    "                i += 1\n",
    "        self.table = table\n",
    "\n",
    "    def sample(self, count):\n",
    "        indices = np.random.randint(low=0, high=len(self.table), size=count)\n",
    "        return [self.table[i] for i in indices]\n",
    "\n",
    "def sigmoid(z):\n",
    "    if z > 6:\n",
    "        return 1.0\n",
    "    elif z < -6:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return 1 / (1 + math.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unknown vocab size: 143\n",
      "Total words in training file: 338\n",
      "Total bytes in training file: 1938\n",
      "Vocab size: 50\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary(\"local.txt\",2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check = vocab.__iter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=list(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2].word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171.04254241\n",
      "100000000.0\n",
      "Filling unigram table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel/__main__.py:101: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "table = UnigramTable(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0, 12, 0, 8]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi = open(\"local.txt\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_word_count=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "starting_alpha=0.025\n",
    "win=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_net(dim, vocab_size):\n",
    "    # Init syn0 with random numbers from a uniform distribution on the interval [-0.5, 0.5]/dim\n",
    "    tmp = np.random.uniform(low=-0.5/dim, high=0.5/dim, size=(vocab_size, dim))\n",
    "    syn0 = tmp\n",
    "  \n",
    "\n",
    "    # Init syn1 with zeros\n",
    "    tmp = np.zeros(shape=(vocab_size, dim))\n",
    "    syn1 = tmp\n",
    "  \n",
    "\n",
    "    return (syn0, syn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " syn0, syn1 = init_net(5, len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print syn1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People are converging on the outskirts of this small town on the borders of East Godavari and Visakhapatnam districts with the single point agenda of getting the Kapu community included in the list of Backward Classes (BCs). This moment gained momentum over the last few weeks in all towns and villages between Vijayawada and East Godavari and also in some Rayalaseema districts.\n",
      "1938\n",
      "inside loop\n",
      "[4, 0, 10, 0, 8, 1, 0, 6, 14, 0, 0, 8, 1, 0, 6, 11, 12, 3, 21, 22, 15, 1, 0, 0, 0, 6, 0, 1, 9, 16, 0, 2, 1, 23, 6, 24, 25, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 3, 0, 0, 0, 3, 11, 12, 3, 0, 2, 26, 0, 0, 5]\n",
      "0 4\n",
      "5\n",
      "1 0\n",
      "6\n",
      "2 10\n",
      "6\n",
      "3 0\n",
      "4\n",
      "4 8\n",
      "2\n",
      "5 1\n",
      "10\n",
      "6 0\n",
      "2\n",
      "7 6\n",
      "4\n",
      "8 14\n",
      "4\n",
      "9 0\n",
      "2\n",
      "10 0\n",
      "4\n",
      "11 8\n",
      "10\n",
      "12 1\n",
      "10\n",
      "13 0\n",
      "4\n",
      "14 6\n",
      "8\n",
      "15 11\n",
      "8\n",
      "16 12\n",
      "8\n",
      "17 3\n",
      "2\n",
      "18 21\n",
      "2\n",
      "19 22\n",
      "8\n",
      "20 15\n",
      "10\n",
      "21 1\n",
      "2\n",
      "22 0\n",
      "4\n",
      "23 0\n",
      "8\n",
      "24 0\n",
      "10\n",
      "25 6\n",
      "4\n",
      "26 0\n",
      "2\n",
      "27 1\n",
      "10\n",
      "28 9\n",
      "4\n",
      "29 16\n",
      "10\n",
      "30 0\n",
      "10\n",
      "31 2\n",
      "8\n",
      "32 1\n",
      "10\n",
      "33 23\n",
      "4\n",
      "34 6\n",
      "6\n",
      "35 24\n",
      "6\n",
      "36 25\n",
      "6\n",
      "37 0\n",
      "4\n",
      "38 0\n",
      "8\n",
      "39 0\n",
      "4\n",
      "40 0\n",
      "8\n",
      "41 0\n",
      "2\n",
      "42 0\n",
      "10\n",
      "43 1\n",
      "8\n",
      "44 0\n",
      "2\n",
      "45 0\n",
      "2\n",
      "46 0\n",
      "4\n",
      "47 2\n",
      "2\n",
      "48 0\n",
      "8\n",
      "49 0\n",
      "4\n",
      "50 3\n",
      "8\n",
      "51 0\n",
      "8\n",
      "52 0\n",
      "4\n",
      "53 0\n",
      "2\n",
      "54 3\n",
      "6\n",
      "55 11\n",
      "6\n",
      "56 12\n",
      "4\n",
      "57 3\n",
      "6\n",
      "58 0\n",
      "6\n",
      "59 2\n",
      "2\n",
      "60 26\n",
      "6\n",
      "61 0\n",
      "5\n",
      "62 0\n",
      "2\n",
      "63 5\n",
      "1\n",
      "\n",
      "1938\n",
      "inside loop\n",
      "[4, 5]\n",
      "0 4\n",
      "1\n",
      "1 5\n",
      "1\n",
      "A massive public meeting is will be convened here on Sunday evening in which former Minister and Kapu leader Mudragada Padmanabham will be the main speaker.\n",
      "1938\n",
      "inside loop\n",
      "[4, 27, 0, 0, 28, 29, 30, 31, 0, 0, 8, 0, 0, 2, 32, 0, 0, 3, 9, 0, 0, 0, 30, 31, 1, 0, 0, 5]\n",
      "0 4\n",
      "2\n",
      "1 27\n",
      "2\n",
      "2 0\n",
      "7\n",
      "3 0\n",
      "2\n",
      "4 28\n",
      "8\n",
      "5 29\n",
      "6\n",
      "6 30\n",
      "2\n",
      "7 31\n",
      "6\n",
      "8 0\n",
      "6\n",
      "9 0\n",
      "6\n",
      "10 8\n",
      "8\n",
      "11 0\n",
      "6\n",
      "12 0\n",
      "6\n",
      "13 2\n",
      "6\n",
      "14 32\n",
      "10\n",
      "15 0\n",
      "4\n",
      "16 0\n",
      "6\n",
      "17 3\n",
      "6\n",
      "18 9\n",
      "4\n",
      "19 0\n",
      "10\n",
      "20 0\n",
      "4\n",
      "21 0\n",
      "2\n",
      "22 30\n",
      "2\n",
      "23 31\n",
      "4\n",
      "24 1\n",
      "7\n",
      "25 0\n",
      "4\n",
      "26 0\n",
      "4\n",
      "27 5\n",
      "3\n",
      "\n",
      "1938\n",
      "inside loop\n",
      "[4, 5]\n",
      "0 4\n",
      "1\n",
      "1 5\n",
      "1\n",
      "Local Kapu leaders are happy that they have got an open support from the YSR Congress and Congress as PCC president N. Raghuveera Reddy, YSR Congress Central Committee member Jakkampudi Vijayalakshmi announced their support to the cause.\n",
      "1938\n",
      "inside loop\n",
      "[4, 0, 9, 0, 10, 0, 0, 33, 13, 34, 0, 0, 35, 36, 1, 37, 17, 3, 17, 18, 0, 0, 0, 0, 0, 37, 17, 0, 0, 0, 0, 0, 0, 0, 35, 7, 1, 0, 5]\n",
      "0 4\n",
      "1\n",
      "1 0\n",
      "4\n",
      "2 9\n",
      "6\n",
      "3 0\n",
      "2\n",
      "4 10\n",
      "4\n",
      "5 0\n",
      "2\n",
      "6 0\n",
      "2\n",
      "7 33\n",
      "6\n",
      "8 13\n",
      "10\n",
      "9 34\n",
      "8\n",
      "10 0\n",
      "4\n",
      "11 0\n",
      "10\n",
      "12 35\n",
      "2\n",
      "13 36\n",
      "8\n",
      "14 1\n",
      "8\n",
      "15 37\n",
      "2\n",
      "16 17\n",
      "2\n",
      "17 3\n",
      "10\n",
      "18 17\n",
      "2\n",
      "19 18\n",
      "4\n",
      "20 0\n",
      "4\n",
      "21 0\n",
      "2\n",
      "22 0\n",
      "10\n",
      "23 0\n",
      "4\n",
      "24 0\n",
      "10\n",
      "25 37\n",
      "8\n",
      "26 17\n",
      "6\n",
      "27 0\n",
      "10\n",
      "28 0\n",
      "4\n",
      "29 0\n",
      "2\n",
      "30 0\n",
      "2\n",
      "31 0\n",
      "2\n",
      "32 0\n",
      "2\n",
      "33 0\n",
      "8\n",
      "34 35\n",
      "9\n",
      "35 7\n",
      "8\n",
      "36 1\n",
      "2\n",
      "37 0\n",
      "4\n",
      "38 5\n",
      "1\n",
      "\n",
      "1938\n",
      "inside loop\n",
      "[4, 5]\n",
      "0 4\n",
      "1\n",
      "1 5\n",
      "1\n",
      "At least 3 to 4 lakh Kapus are expected to take part in the rally. Leaders from Chittoor, Nellore, Guntur, Krishna, East and West Godavari and Visakhapatnam districts have already started for the venue in hired services.\n",
      "1938\n",
      "inside loop\n",
      "[4, 0, 0, 0, 7, 0, 0, 38, 10, 0, 7, 0, 39, 2, 1, 0, 0, 36, 0, 0, 0, 0, 11, 3, 0, 12, 3, 21, 22, 13, 0, 0, 40, 1, 0, 2, 0, 0, 5]\n",
      "0 4\n",
      "4\n",
      "1 0\n",
      "4\n",
      "2 0\n",
      "7\n",
      "3 0\n",
      "7\n",
      "4 7\n",
      "6\n",
      "5 0\n",
      "6\n",
      "6 0\n",
      "10\n",
      "7 38\n",
      "8\n",
      "8 10\n",
      "6\n",
      "9 0\n",
      "6\n",
      "10 7\n",
      "6\n",
      "11 0\n",
      "4\n",
      "12 39\n",
      "6\n",
      "13 2\n",
      "4\n",
      "14 1\n",
      "2\n",
      "15 0\n",
      "6\n",
      "16 0\n",
      "8\n",
      "17 36\n",
      "6\n",
      "18 0\n",
      "4\n",
      "19 0\n",
      "2\n",
      "20 0\n",
      "10\n",
      "21 0\n",
      "2\n",
      "22 11\n",
      "10\n",
      "23 3\n",
      "2\n",
      "24 0\n",
      "8\n",
      "25 12\n",
      "4\n",
      "26 3\n",
      "10\n",
      "27 21\n",
      "2\n",
      "28 22\n",
      "10\n",
      "29 13\n",
      "4\n",
      "30 0\n",
      "2\n",
      "31 0\n",
      "10\n",
      "32 40\n",
      "10\n",
      "33 1\n",
      "4\n",
      "34 0\n",
      "6\n",
      "35 2\n",
      "2\n",
      "36 0\n",
      "2\n",
      "37 0\n",
      "2\n",
      "38 5\n",
      "3\n",
      "\n",
      "1938\n",
      "inside loop\n",
      "[4, 5]\n",
      "0 4\n",
      "1\n",
      "1 5\n",
      "1\n",
      "According to East Godavari and Rajamahendravaram Urban district SPs, they have deployed around 20 DSPs and around 2,000 police personnel as part of the bandobust. Thought the demand for including Kapu community in the Backward Classes is old.\n",
      "1938\n",
      "inside loop\n",
      "[4, 0, 7, 11, 12, 3, 0, 0, 0, 0, 33, 13, 0, 41, 0, 0, 3, 41, 0, 0, 0, 18, 39, 6, 1, 0, 0, 1, 0, 40, 0, 9, 16, 2, 1, 24, 25, 29, 0, 5]\n",
      "0 4\n",
      "5\n",
      "1 0\n",
      "3\n",
      "2 7\n",
      "4\n",
      "3 11\n",
      "6\n",
      "4 12\n",
      "6\n",
      "5 3\n",
      "2\n",
      "6 0\n",
      "8\n",
      "7 0\n",
      "10\n",
      "8 0\n",
      "2\n",
      "9 0\n",
      "10\n",
      "10 33\n",
      "4\n",
      "11 13\n",
      "10\n",
      "12 0\n",
      "4\n",
      "13 41\n",
      "6\n",
      "14 0\n",
      "10\n",
      "15 0\n",
      "4\n",
      "16 3\n",
      "4\n",
      "17 41\n",
      "2\n",
      "18 0\n",
      "2\n",
      "19 0\n",
      "2\n",
      "20 0\n",
      "2\n",
      "21 18\n",
      "4\n",
      "22 39\n",
      "10\n",
      "23 6\n",
      "8\n",
      "24 1\n",
      "8\n",
      "25 0\n",
      "10\n",
      "26 0\n",
      "8\n",
      "27 1\n",
      "6\n",
      "28 0\n",
      "6\n",
      "29 40\n",
      "2\n",
      "30 0\n",
      "8\n",
      "31 9\n",
      "2\n",
      "32 16\n",
      "8\n",
      "33 2\n",
      "4\n",
      "34 1\n",
      "4\n",
      "35 24\n",
      "2\n",
      "36 25\n",
      "8\n",
      "37 29\n",
      "2\n",
      "38 0\n",
      "3\n",
      "39 5\n",
      "3\n",
      "\n",
      "1938\n",
      "inside loop\n",
      "[4, 5]\n",
      "0 4\n",
      "1\n",
      "1 5\n",
      "1\n",
      "A number of agitations have organised on this issue in the past, the particular meeting got importance as some sections of youth and middle-aged people in this community are unhappy with the TDP governmentâ€™s decision of appointing Justice Manjunatha Commission to submit report on how to include the people living below poverty line in Kapu, Telaga, Balija and Ontari in the BC list. However, S.G. Rama Rao, State Chairman of Kapu Advocates Forum said the government can directly include Kapus the BC list in accordance with 5 January, 2007 judgment given by Justice Rohini to implement the GO 30 in toto which facilitates the State to include Kapu, Telaga, Balija and Ontari in the BC list.\n",
      "1938\n",
      "inside loop\n",
      "[4, 27, 0, 6, 0, 13, 0, 8, 14, 0, 2, 1, 0, 1, 0, 28, 34, 0, 18, 26, 0, 6, 0, 3, 0, 42, 2, 14, 16, 10, 0, 15, 1, 0, 0, 0, 6, 0, 43, 0, 0, 7, 0, 0, 8, 0, 7, 19, 1, 42, 0, 0, 0, 0, 2, 44, 45, 46, 3, 47, 2, 1, 20, 48, 0, 0, 0, 0, 49, 0, 6, 9, 0, 0, 0, 1, 0, 0, 0, 19, 38, 1, 20, 23, 2, 0, 15, 0, 0, 0, 0, 0, 0, 43, 0, 7, 0, 1, 0, 0, 2, 0, 32, 0, 1, 49, 7, 19, 44, 45, 46, 3, 47, 2, 1, 20, 48, 5]\n",
      "0 4\n",
      "1\n",
      "1 27\n",
      "5\n",
      "2 0\n",
      "7\n",
      "3 6\n",
      "4\n",
      "4 0\n",
      "9\n",
      "5 13\n",
      "10\n",
      "6 0\n",
      "8\n",
      "7 8\n",
      "6\n",
      "8 14\n",
      "6\n",
      "9 0\n",
      "2\n",
      "10 2\n",
      "6\n",
      "11 1\n",
      "10\n",
      "12 0\n",
      "2\n",
      "13 1\n",
      "4\n",
      "14 0\n",
      "2\n",
      "15 28\n",
      "6\n",
      "16 34\n",
      "4\n",
      "17 0\n",
      "4\n",
      "18 18\n",
      "4\n",
      "19 26\n",
      "4\n",
      "20 0\n",
      "6\n",
      "21 6\n",
      "6\n",
      "22 0\n",
      "6\n",
      "23 3\n",
      "10\n",
      "24 0\n",
      "8\n",
      "25 42\n",
      "10\n",
      "26 2\n",
      "10\n",
      "27 14\n",
      "6\n",
      "28 16\n",
      "10\n",
      "29 10\n",
      "8\n",
      "30 0\n",
      "2\n",
      "31 15\n",
      "6\n",
      "32 1\n",
      "8\n",
      "33 0\n",
      "4\n",
      "34 0\n",
      "2\n",
      "35 0\n",
      "6\n",
      "36 6\n",
      "8\n",
      "37 0\n",
      "2\n",
      "38 43\n",
      "2\n",
      "39 0\n",
      "4\n",
      "40 0\n",
      "2\n",
      "41 7\n",
      "6\n",
      "42 0\n",
      "10\n",
      "43 0\n",
      "4\n",
      "44 8\n",
      "6\n",
      "45 0\n",
      "10\n",
      "46 7\n",
      "10\n",
      "47 19\n",
      "6\n",
      "48 1\n",
      "6\n",
      "49 42\n",
      "4\n",
      "50 0\n",
      "10\n",
      "51 0\n",
      "6\n",
      "52 0\n",
      "4\n",
      "53 0\n",
      "2\n",
      "54 2\n",
      "10\n",
      "55 44\n",
      "8\n",
      "56 45\n",
      "6\n",
      "57 46\n",
      "10\n",
      "58 3\n",
      "8\n",
      "59 47\n",
      "4\n",
      "60 2\n",
      "2\n",
      "61 1\n",
      "4\n",
      "62 20\n",
      "8\n",
      "63 48\n",
      "4\n",
      "64 0\n",
      "8\n",
      "65 0\n",
      "6\n",
      "66 0\n",
      "4\n",
      "67 0\n",
      "10\n",
      "68 49\n",
      "6\n",
      "69 0\n",
      "10\n",
      "70 6\n",
      "10\n",
      "71 9\n",
      "8\n",
      "72 0\n",
      "4\n",
      "73 0\n",
      "10\n",
      "74 0\n",
      "8\n",
      "75 1\n",
      "10\n",
      "76 0\n",
      "6\n",
      "77 0\n",
      "6\n",
      "78 0\n",
      "8\n",
      "79 19\n",
      "8\n",
      "80 38\n",
      "4\n",
      "81 1\n",
      "10\n",
      "82 20\n",
      "8\n",
      "83 23\n",
      "10\n",
      "84 2\n",
      "8\n",
      "85 0\n",
      "10\n",
      "86 15\n",
      "4\n",
      "87 0\n",
      "4\n",
      "88 0\n",
      "8\n",
      "89 0\n",
      "6\n",
      "90 0\n",
      "10\n",
      "91 0\n",
      "8\n",
      "92 0\n",
      "6\n",
      "93 43\n",
      "6\n",
      "94 0\n",
      "2\n",
      "95 7\n",
      "2\n",
      "96 0\n",
      "8\n",
      "97 1\n",
      "6\n",
      "98 0\n",
      "8\n",
      "99 0\n",
      "4\n",
      "100 2\n",
      "10\n",
      "101 0\n",
      "10\n",
      "102 32\n",
      "8\n",
      "103 0\n",
      "6\n",
      "104 1\n",
      "8\n",
      "105 49\n",
      "10\n",
      "106 7\n",
      "4\n",
      "107 19\n",
      "4\n",
      "108 44\n",
      "10\n",
      "109 45\n",
      "8\n",
      "110 46\n",
      "8\n",
      "111 3\n",
      "4\n",
      "112 47\n",
      "10\n",
      "113 2\n",
      "6\n",
      "114 1\n",
      "4\n",
      "115 20\n",
      "6\n",
      "116 48\n",
      "6\n",
      "117 5\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "with open(\"local.txt\", 'r') as fi:\n",
    "    for lines in fi:\n",
    "        line = lines.strip()\n",
    "        print line\n",
    "        print fi.tell()\n",
    "        print \"inside loop\"\n",
    "        sent = vocab.indices(['<bol>'] + line.split() + ['<eol>'])\n",
    "        print sent\n",
    "        for sent_pos, token in enumerate(sent):\n",
    "            print sent_pos,token\n",
    "            if current_word_count % 100 == 0:\n",
    "                current_word_count += 1\n",
    "                    # Recalculate alpha\n",
    "                alpha = starting_alpha * (1 - float(current_word_count) / vocab.word_count)\n",
    "                if alpha < starting_alpha * 0.0001: alpha = starting_alpha * 0.0001\n",
    "            current_win = np.random.randint(low=1, high=win+1)\n",
    "            context_start = max(sent_pos - current_win, 0)\n",
    "            context_end = min(sent_pos + current_win + 1, len(sent))\n",
    "            context = sent[context_start:sent_pos] + sent[sent_pos+1:context_end]\n",
    "            print len(context)\n",
    "            for context_word in context:\n",
    "                neu1e = np.zeros(5)\n",
    "                classifiers = [(token, 1)] + [(target, 0) for target in table.sample(1)]\n",
    "                for target, label in classifiers:\n",
    "                    z = np.dot(syn0[context_word], syn1[target])\n",
    "                    p = sigmoid(z)\n",
    "                    g = alpha * (label - p)\n",
    "                    neu1e += g * syn1[target]              # Error to backpropagate to syn0\n",
    "                    syn1[target] += g * syn0[context_word] # Update syn1\n",
    "\n",
    "                        # Update syn0\n",
    "                syn0[context_word] += neu1e\n",
    "            current_word_count += 1\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save(vocab, syn0, fo, binary):\n",
    "    print 'Saving model to', fo\n",
    "    dim = len(syn0[0])\n",
    "    if binary:\n",
    "        fo = open(fo, 'wb')\n",
    "        fo.write('%d %d\\n' % (len(syn0), 5))\n",
    "        fo.write('\\n')\n",
    "        for token, vector in zip(vocab, syn0):\n",
    "            fo.write('%s ' % token.word)\n",
    "            for s in vector:\n",
    "                fo.write(struct.pack('f', s))\n",
    "            fo.write('\\n')\n",
    "    else:\n",
    "        fo = open(fo, 'w')\n",
    "        fo.write('%d %d\\n' % (len(syn0), 5))\n",
    "        for token, vector in zip(vocab, syn0):\n",
    "            word = token.word\n",
    "            vector_str = ' '.join([str(s) for s in vector])\n",
    "            fo.write('%s %s\\n' % (word, vector_str))\n",
    "\n",
    "    fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to localmodel.txt\n"
     ]
    }
   ],
   "source": [
    "save(vocab,syn0,\"localmodel.txt\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to kapus\n"
     ]
    }
   ],
   "source": [
    "save(vocab,syn0,\"kapus\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
